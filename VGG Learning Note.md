VGG Learning Notes
==============

参考：

[一文读懂VGG网络](https://zhuanlan.zhihu.com/p/41423739)

### 1 VGG 原理

VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）。对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。

5x5卷积看做一个小的全连接网络在5x5区域滑动，我们可以先用一个3x3的卷积滤波器卷积，然后再用一个全连接层连接这个3x3卷积输出，这个全连接层我们也可以看做一个3x3卷积层。这样我们就可以用两个3x3卷积级联（叠加）起来代替一个 5x5卷积。

![](https://pic2.zhimg.com/80/v2-d3bdfd338d8999d2ce1dde2082fa95e1_hd.jpg)

### 2 VGG 网络结构

![](https://pic4.zhimg.com/80/v2-ea924e733676e0da534f677a97c98653_hd.jpg)

VGG16包含了16个隐藏层（13个卷积层和3个全连接层），如上图中的D列所示

VGG19包含了19个隐藏层（16个卷积层和3个全连接层），如上图中的E列所示

VGG网络的结构非常一致，从头到尾全部使用的是3x3的卷积和2x2的max pooling。

### 3 VGG优缺点

* VGG优点

1. VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）。

2. 几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好：

3. 验证了通过不断加深网络结构可以提升性能。

* VGG缺点

1. VGG耗费更多计算资源，并且使用了更多的参数（这里不是3x3卷积的锅），导致更多的内存占用（140M）。其中绝大多数的参数都是来自于第一个全连接层。VGG可是有3个全连接层啊

